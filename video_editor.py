# -*- coding: utf-8 -*-
"""Video_editor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lchp3RUzMpVn27pBN7g3IJ_ZP4S__4qv
"""

from google.colab import files
uploaded = files.upload()  # Upload your video (e.g., "my_video.mp4")

!ffmpeg -i input.mp4 -vn -q:a 0 -map a audio.mp3

import whisper

model = whisper.load_model("base")  # Use "small", "medium", or "large" for better accuracy
result = model.transcribe("audio.mp3")
print(result["text"])

transcription_segments = result["segments"]

print(transcription_segments)

!pip install pydub

from pydub import AudioSegment
from pydub.silence import detect_silence

audio = AudioSegment.from_file("audio.mp3")
silence_ranges = detect_silence(
    audio,
 min_silence_len=500,  # 500ms minimum silence
    silence_thresh=-50    # -50 dBFS threshold
)

import re

filler_words = ["um", "uh", "ah", "like", "you know"]
trim_points = []

for segment in transcription_segments:
    if re.search(r'\b(' + '|'.join(filler_words) + r')\b', segment["text"], re.IGNORECASE):
      trim_points.append((segment["start"], segment["end"]))

all_trim_ranges = trim_points + [(start/1000, end/1000) for (start,end) in silence_ranges]

import subprocess

def trim_video(input_path, output_path, keep_ranges):
    filter_complex = []
    inputs = []

    for i, (start, end) in enumerate(keep_ranges):
        inputs.append(f"between(t,{start},{end})")

    filter_str = f"select='{' + '.join(inputs)}',setpts=N/FRAME_RATE/TB"
    cmd = [
        "ffmpeg",
        "-i", input_path,
        "-vf", filter_str,
        "-af", f"aselect='{' + '.join(inputs)}',asetpts=N/SR/TB",
        "-c:v", "libx264",
        "-c:a", "aac",
        output_path
    ]
    subprocess.run(cmd)  # This line was not indented

# Example usage:
keep_ranges = [(0, 2.5), (4.0, 6.0)]  # Remove 2.5-4.0 seconds
trim_video("input.mp4", "output.mp4", keep_ranges)

